{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Analysis of Tweets Containing the CometLanding Hashtag</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preprocessing input CSV data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File contains 51 invalid rows!\n",
      "Refining the data given and storing it a new file...\n",
      "Refined data can be found in 'data/CometLanding_refined.csv'.\n"
     ]
    }
   ],
   "source": [
    "from parsing import *\n",
    "cr = CensusReader(\"data/CometLanding.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>CensusReader class __init__() method</h3>\n",
    "<p>The __init__() method in the CensusReader class calls read_csv() from pandas on the file CometLanding.csv.<br/>\n",
    "    This creates a DataFrame which is then parsed with validateFile(); invalid tweets are removed in this process.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, fileName):\n",
    "    self.fileName = fileName\n",
    "    self.data = pd.read_csv(fileName)\n",
    "    \n",
    "    self.data[\"valid\"] = True\n",
    "    self.validateFile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>validateFile() method</h3>\n",
    "<p>The validateFile() method finds all duplicte entries in the DataFrame (by their string tweet ID).<br/>\n",
    "    It then removes all the duplicate entries from the DataFrame, before printing the number of duplicate tweets (invalid rows) there were.<br/>\n",
    "    Finally, it outputs the remaining (valid, non-duplicate) entries/tweets in the DataFrame to a new CSV file.<br/>\n",
    "    It outputs it to the filename the data was read in from, with _refined added before the .csv extension; the data is converted from a DataFrame into CSV format using the to_csv() method.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateFile(self):\n",
    "        #check duplication\n",
    "        self.data[\"valid\"] = self.data[\"valid\"] & ~(self.data.duplicated(\"id_str\"))\n",
    "\n",
    "        invalidData = self.data.query(\"valid == False\")\n",
    "        self.data = self.data.query(\"valid == True\")\n",
    "\n",
    "        # Drops the 'valid' column since it is no longer needed.\n",
    "        self.data.drop('valid', axis=1, inplace=True)\n",
    "\n",
    "        invalidRows = len(invalidData)\n",
    "\n",
    "        if (invalidRows > 0):\n",
    "            if invalidRows == 1:\n",
    "                print(\"File contains 1 invalid row!\")\n",
    "            else:\n",
    "                print(\"File contains \"+str(invalidRows)+ \" invalid rows!\")\n",
    "\n",
    "            #make a new file\n",
    "            if self.fileName[-4:] == \".csv\":\n",
    "                print(\"Refining the data given and storing it a new file...\")\n",
    "                newFileName = self.fileName[:-4] + \"_refined.csv\"\n",
    "                self.data.to_csv(newFileName)\n",
    "                print(\"Refined data can be found in \\'\" + newFileName + \"\\'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Counting the numbers of tweets, replies, retweets, and users, and calculating average user activity.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsing import *\n",
    "\n",
    "cr = CensusReader(\"data/CometLanding_refined.csv\")\n",
    "retweets = cr.retweetCount()\n",
    "replies = cr.replyCount()\n",
    "tweets = cr.tweetCount()\n",
    "users = cr.userCount()\n",
    "\n",
    "print(\"\\nThere were \" + str(tweets) + \" tweets in total.\")\n",
    "print(\"There were \" + str(replies) + \" replies in total.\")\n",
    "print(\"There were \" + str(retweets) + \" retweets in total.\\n\")\n",
    "\n",
    "print(\"There were \" + str(users) + \" users tweeting in the dataset.\\n\")\n",
    "\n",
    "print(\"The average number of tweets by a user in the dataset was \" + str(tweets / users) + \".\")\n",
    "print(\"The average number of replies by a user in the dataset was \" + str(replies / users) + \".\")\n",
    "print(\"The average number of retweets by a user in the dataset was \" + str(retweets / users) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>retweetCount() method</h3>\n",
    "<p>The retweetCount() method first finds if the tweet text for each item in the DataFrame from the CSV data starts with \"RT\", indicating it is a retweet.<br/>\n",
    "    Each result is added to a new list of Boolean values; the sum() method is then used to count the number of True values in the list (i.e. retweets).<br/>\n",
    "    The value of the sum function is then returned.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retweetCount(self):\n",
    "    return (self.data['text'].str.startswith(\"RT\")).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>replyCount() method</h3>\n",
    "<p>The replyCount() method first finds if the 'in_reply_to_screen_name' field for each item in the DataFrame from the CSV isn't empty, indicating it is a reply.<br/>\n",
    "    Each result is added to a new list of Boolean values; the sum() method is then used to count the number of True values in the list (i.e. replies).<br/>\n",
    "    The value of the sum function is then returned.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replyCount(self):\n",
    "    return (self.data['in_reply_to_screen_name'].notnull()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>tweetCount() method</h3>\n",
    "<p>The tweetCount() method first finds the number of unique tweets. It does this by taking all parsable entries in the DataFrame (from which duplicates have already been dropped).<br/>\n",
    "It then finds the length of the resulting DataFrame (of all unique tweets), representing the total number of tweets of any kind.<br/>\n",
    "To then find the number of tweets that are not replies or retweets, we then subtract the result of the replyCount() and retweetCount() methods from the number of unique tweets found.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweetCount(self):\n",
    "    return len(self.data['entities_str'].notnull()) - self.replyCount() - self.retweetCount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>userCount() method</h3>\n",
    "<p>The userCount() method first finds entries in the DataFrane who have unique posting users (i.e. removing all but one tweet posted by each user with one or more tweet in the dataset)<br/>\n",
    "    It does this with the pandas drop_duplicates() method.<br/>\n",
    "The length of the resulting DataFrame is then returned, representing the number of unique uesers who posted tweets in the dataset.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userCount(self):\n",
    "    return len(self.data.drop_duplicates(subset=['from_user_id_str']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Pie chart showing composition of activity by type</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsing import *\n",
    "from plotter import *\n",
    "\n",
    "cr = CensusReader(\"data/CometLanding_refined.csv\")\n",
    "\n",
    "retweets = cr.retweetCount()\n",
    "replies = cr.replyCount()\n",
    "tweets = cr.tweetCount()\n",
    "\n",
    "plotter = Plotter()\n",
    "plotter.pieChart(tweets, retweets, replies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>pieChart() method</h3>\n",
    "<p>The pieChart() method begins by adding the numbers of tweets, retweets, and replies in the DataFrame.<br/>\n",
    "    It then finds the percentage proportion of all activity for each activity type (tweets, retweets, and replies).<br/>It then creates lists of labels for the legend, the \"slice\" sizes, and colours of the pie chart.<br/>\n",
    "    These and other arguments are then passed to plt.pie() and other plt() methods to generate and then display the pie chart (plt represents matplotlib.pyplot).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pieChart(self, tweets, retweets, replies):\n",
    "    total = tweets + retweets + replies\n",
    "    # The slices will be ordered and plotted counter-clockwise.\n",
    "    percents = [(float(tweets)/float(total)*100.0), (float(retweets)/float(total)*100.0),(float(replies)/float(total)*100.0)]\n",
    "\n",
    "    labels = 'Tweets (' + str(percents[0]) + '%)', 'Retweets (' + str(percents[1]) + '%)', 'Replies (' + str(percents[2]) + '%)'\n",
    "    fracs = [tweets, retweets, replies]\n",
    "    colors = ['#ff4d4d', '#0FAC36', '#0F18AC'] # red, green, blue\n",
    "\n",
    "    patches, texts = plt.pie(fracs, colors=colors, shadow=True, startangle=90)\n",
    "    plt.legend(patches, labels, loc=\"best\")\n",
    "    plt.axis('equal')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.title('Pie Chart Showing Frequencies of Different Activity Types')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Bar chart showing composition of activity by type</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsing import *\n",
    "from plotter import *\n",
    "\n",
    "cr = CensusReader(\"data/CometLanding_refined.csv\")\n",
    "\n",
    "retweets = cr.retweetCount()\n",
    "replies = cr.replyCount()\n",
    "tweets = cr.tweetCount()\n",
    "\n",
    "\n",
    "plotter = Plotter()\n",
    "plotter.barChart(tweets, retweets, replies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The barChart() method</h3>\n",
    "<p>The barChart() method is very similar to the pieChart() method, using the numbers of tweets, retweets, and replies in the DataFrame.<br/>\n",
    "    Again, values to be used as parameters for the bar chart are generated from the fequency of each activity type; these are used with their Names, as well as axis labels and a title to generate the bar chart, again with plt as matplotlib.pyplot.<br/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barChart(self, tweets, retweets, replies):\n",
    "    vals = [tweets, retweets, replies]\n",
    "    labels = ('Tweets', 'Retweets', 'Replies')\n",
    "    n_groups = len(vals)\n",
    "    bar_width = 1/1.5\n",
    "    pos = np.arange(len(labels))\n",
    "    \n",
    "    plt.bar(pos, vals, align='center', alpha=0.5)\n",
    "    plt.xticks(pos, labels)\n",
    "    plt.ylabel('Absolute Frequency')\n",
    "    plt.xlabel('Activity Type')\n",
    "    plt.title('Bar Chart Showing Frequencies of Different Activity Types')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Finding the 10 most common hashtags used</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsing import *\n",
    "\n",
    "cr = CensusReader(\"data/CometLanding_refined.csv\")\n",
    "print(cr.mostPopHashtags(10, False))\n",
    "print(\"\\n\\n\")\n",
    "print(cr.mostPopHashtags(10, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The mostPopHashtags() method</h3>\n",
    "<p>The mostPopHashtags() method begins by getting sorted list of hashtags and their numbers of occurances from the getHTagsAndCounts() method.<br/>\n",
    "    The method then checks if the user wants to exclude variants of the #CometLanding hashtag from the results; if so, the method will iterate over the items in the list up to the number to be printed, removing any matches to the #CometLanding hashtag and then moving back.<br/>\n",
    "    The method then iterates over the resultant list of hashtags up to the nth largest to be printed, printing each hashtag and the number of tweets in the DataFrame it appears in.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostPopHashtags(self, number, excludeCometLanding):\n",
    "    sortedHTagsAndCounts = sorted(self.getHTagsAndCounts(), key = itemgetter(1), reverse=True)\n",
    "    returnString = \"\"\n",
    "    \n",
    "    if excludeCometLanding:\n",
    "        max = number - 1\n",
    "        x = 0\n",
    "        while x < max:\n",
    "            if sortedHTagsAndCounts[x][0].lower() == \"cometlanding\":\n",
    "                del sortedHTagsAndCounts[x]\n",
    "            else: x += 1\n",
    "    \n",
    "    for x in range(0,number):\n",
    "        returnString += str(x + 1) + \". #\" + sortedHTagsAndCounts[x][0] + \" : \" + str(sortedHTagsAndCounts[x][1]) + \" tweets\\n\"\n",
    "    \n",
    "    return returnString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The getHTagsAndCounts() method</h3>\n",
    "<p>The getHTagsAndCounts() method begins by getting a list of every hashtag; each is present in the list the number of times it is tweeted as hashtags are extracted from tweets and added to the list for each tweet. This is done in the getHashTags() method.<br/>\n",
    "    This list is then sorted, before a list without duplicates is found using the removeDuplicates() method.<br/>\n",
    "    This new list without duplicates is then iterated over; each hashtag in it, and the number of times it is present in the original list of hashtags (found using a Counter) is added in a new array item in a new 2D array, hTagsAndCounts, containing each hashtag, and the number of times it is present in a tweet in the DataFrame.<br/>\n",
    "    This new 2D array is then returned.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHTagsAndCounts(self):\n",
    "    hashtags = sorted(self.getHashTags(), reverse=False)\n",
    "    hashtagsNoDuplicates = self.removeDuplicates(hashtags)\n",
    "    hTagsAndCounts = []\n",
    "    counter = Counter(hashtags)\n",
    "    for ht in hashtagsNoDuplicates:\n",
    "        count = counter[ht] # hashtags.count(ht)\n",
    "        hTagsAndCounts.append([ht, count])\n",
    "    return hTagsAndCounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The getHashTags() method</h3>\n",
    "<p>The getHashTags() method generates a list of each hashtag each time it is in a tweet in the DataFrame.<br/>\n",
    "It begins by removing all fields but 'entities_str' for each entry in the DataFrame using the loc pandas function.<br/>\n",
    "    It then generates a JSON object from the 'entities_str' field for each entry in the DataFrame using json.load().<br/>\n",
    "    The JSON array of hashtags are then extracted from this, and iterated over; each hashtag in the JSON hashtag list in the JSON entities object for each entry (tweet) is also then iterated over. The text of each hashtag is then appended to the list of hashtags being build.<br/>\n",
    "    When all iteration terminates, the resultant list of hashtags is returned.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHashTags(self):\n",
    "    #     hashtags = self.data.groupby('entities_str').count().sort_values(by=['id_str'], ascending=False).head(number)\n",
    "    data = self.data\n",
    "    hashtags = []\n",
    "    jsonItems = data.loc[:, 'entities_str'] # lst of JSON hashtag items\n",
    "    # each JSON hashtag item has syntax: {\"\"hashtags\"\":[{\"\"text\"\":\"\"67P\"\",\"\"indices\"\":[58,62]},{\"\"text\"\":\"\"CometWatch\"\",\"\"indices\"\":[127,138]},{\"\"text\"\":\"\"CometLanding\"\",\"\"indices\"\":[139,140]}],\"\"symbols\"\":[],\"\"user_mentions\"\":[{\"\"screen_name\"\":\"\"ESA_Rosetta\"\",\"\"name\"\":\"\"ESA Rosetta Mission\"\",\"\"id\"\":253536357,\"\"id_str\"\":\"\"253536357\"\",\"\"indices\"\":[3,15]}],\"\"urls\"\":[{\"\"url\"\":\"\"http://t.co/Z2A14Jorv6\"\",\"\"expanded_url\"\":\"\"http://youtu.be/4a3eY5siRRk\"\",\"\"display_url\"\":\"\"youtu.be/4a3eY5siRRk\"\",\"\"indices\"\":[104,126]}]}\".\n",
    "    for JSONString in jsonItems:\n",
    "        if not type(JSONString) is str: continue\n",
    "        parsedJSON = json.loads(JSONString)\n",
    "        JSONHashTagsElement = parsedJSON['hashtags']\n",
    "        for JSONHashTag in JSONHashTagsElement:\n",
    "            hashtags.append(JSONHashTag['text'])\n",
    "    return hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The removeDuplicates() method</h3>\n",
    "<p>Copied from <a href=\"https://www.peterbe.com/plog/uniqifiers-benchmark\">https://www.peterbe.com/plog/uniqifiers-benchmark</a>.<br/>\n",
    "    This method adds all the items in the list seq to a dictionary as keys; if an identical item is added it will override the previous entry for the identical key, thus eliminating duplicates.<br/>\n",
    "    The keyset from the dictionary, copied from the seq list, is then returned.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDuplicates(self, seq):\n",
    "    # Not order preserving\n",
    "    keys = {}\n",
    "    for e in seq:\n",
    "        keys[e] = 1\n",
    "    return keys.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Hashtag wordcloud</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsing import *\n",
    "import json\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = CensusReader(\"data/CometLanding_refined.csv\").data\n",
    "hashTags = data.loc[:, 'entities_str']\n",
    "words = []\n",
    "for i, v in hashTags.iteritems():\n",
    "    try:\n",
    "        j = json.loads(v)\n",
    "        for tag in j['hashtags']:\n",
    "            if tag['text'].lower() != \"cometlanding\":\n",
    "                words.append(tag['text'])\n",
    "    except TypeError:\n",
    "        pass\n",
    "\n",
    "wordcloud = WordCloud(width=1000, height=500).generate(\" \".join(words))\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsing import *\n",
    "\n",
    "cr = CensusReader(\"data/CometLanding_refined.csv\")\n",
    "print (cr.appUsed())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsing import *\n",
    "from plotter import *\n",
    "\n",
    "cr = CensusReader(\"data/CometLanding_refined.csv\")\n",
    "data = cr.data\n",
    "\n",
    "plotter = Plotter()\n",
    "\n",
    "plotter.tweetsTimeLine(data)\n",
    "plotter.retweetsTimeLine(data)\n",
    "plotter.repliesTimeLine(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsing import *\n",
    "from plotter import *\n",
    "\n",
    "plotter = Plotter()\n",
    "\n",
    "print(\"Analysing user interactions.\\n\")\n",
    "\n",
    "data = CensusReader(\"data/CometLanding_refined.csv\").data\n",
    "\n",
    "replies = data[data['in_reply_to_screen_name'].notnull()]\n",
    "retweets = data[data['text'].str.startswith(\"RT\") == True]\n",
    "\n",
    "mentions = data[data['text'].str.contains(\"@\") == True]\n",
    "mentions =  mentions[mentions['in_reply_to_screen_name'].notnull() == False]\n",
    "mentions = mentions[mentions['text'].str.startswith(\"RT\") == False]\n",
    "\n",
    "print(\"There were \" + str(len(replies)) + \" replies prior to processing.\")\n",
    "print(\"There were \" + str(len(retweets)) + \" retweets prior to processing.\")\n",
    "print(\"There were \" + str(len(mentions)) + \" mentions containing mentions prior to processing.\\n\")\n",
    "\n",
    "formattedRetweets = plotter.retweetsToTwoUsers(retweets)\n",
    "formattedReplies = plotter.repliesToTwoUsers(replies)\n",
    "formattedMentions = plotter.mentionsToTwoUsers(mentions)\n",
    "\n",
    "interactions = formattedReplies + formattedRetweets + formattedMentions\n",
    "\n",
    "retweets = len(formattedRetweets)\n",
    "replies = len(formattedReplies)\n",
    "mentions = len(formattedMentions)\n",
    "\n",
    "print(\"There were \" + str(replies) + \" replies after processing.\")\n",
    "print(\"There were \" + str(retweets) + \" retweets after processing.\")\n",
    "print(\"There were \" + str(mentions) + \" mentions after processing.\")\n",
    "print(\"Note: a tweet containing >0 mentions can contain >1 mention.\\n\")\n",
    "\n",
    "print(\"There were \" + str(len(interactions)) + \" interactions in total after processing.\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotter import *\n",
    "from parsing import *\n",
    "\n",
    "plotter = Plotter()\n",
    "\n",
    "data = CensusReader(\"data/CometLanding_refined.csv\").data\n",
    "\n",
    "replies = data[data['in_reply_to_screen_name'].notnull()]\n",
    "retweets = data[data['text'].str.startswith(\"RT\") == True]\n",
    "\n",
    "mentions = data[data['text'].str.contains(\"@\") == True]\n",
    "mentions =  mentions[mentions['in_reply_to_screen_name'].notnull() == False]\n",
    "mentions = mentions[mentions['text'].str.startswith(\"RT\") == False]\n",
    "\n",
    "formattedRetweets = plotter.retweetsToTwoUsers(retweets)\n",
    "formattedReplies = plotter.repliesToTwoUsers(replies)\n",
    "formattedMentions = plotter.mentionsToTwoUsers(mentions)\n",
    "\n",
    "interactions = np.concatenate((formattedReplies, formattedMentions, formattedRetweets), axis=0)\n",
    "\n",
    "plotter = Plotter()\n",
    "plotter.networkGraph(interactions, \"interactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotter import *\n",
    "from parsing import *\n",
    "\n",
    "plotter = Plotter()\n",
    "\n",
    "data = CensusReader(\"data/CometLanding_refined.csv\").data\n",
    "\n",
    "replies = data[data['in_reply_to_screen_name'].notnull()]\n",
    "retweets = data[data['text'].str.startswith(\"RT\") == True]\n",
    "\n",
    "mentions = data[data['text'].str.contains(\"@\") == True]\n",
    "mentions =  mentions[mentions['in_reply_to_screen_name'].notnull() == False]\n",
    "mentions = mentions[mentions['text'].str.startswith(\"RT\") == False]\n",
    "\n",
    "formattedRetweets = plotter.retweetsToTwoUsers(retweets)\n",
    "formattedReplies = plotter.repliesToTwoUsers(replies)\n",
    "formattedMentions = plotter.mentionsToTwoUsers(mentions)\n",
    "\n",
    "plotter = Plotter()\n",
    "plotter.networkGraph(formattedRetweets, \"retweets\")\n",
    "plotter.networkGraph(formattedReplies, \"replies\")\n",
    "plotter.networkGraph(formattedMentions, \"mentions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotter import *\n",
    "from parsing import *\n",
    "\n",
    "plotter = Plotter()\n",
    "\n",
    "data = CensusReader(\"data/CometLanding_refined.csv\").data\n",
    "\n",
    "replies = data[data['in_reply_to_screen_name'].notnull()]\n",
    "retweets = data[data['text'].str.startswith(\"RT\") == True]\n",
    "\n",
    "mentions = data[data['text'].str.contains(\"@\") == True]\n",
    "mentions =  mentions[mentions['in_reply_to_screen_name'].notnull() == False]\n",
    "mentions = mentions[mentions['text'].str.startswith(\"RT\") == False]\n",
    "\n",
    "formattedRetweets = plotter.retweetsToTwoUsers(retweets)\n",
    "formattedReplies = plotter.repliesToTwoUsers(replies)\n",
    "formattedMentions = plotter.mentionsToTwoUsers(mentions)\n",
    "\n",
    "interactions = formattedReplies + formattedRetweets + formattedMentions\n",
    "\n",
    "plotter = Plotter()\n",
    "plotter.interactionsPieChart(len(formattedRetweets), len(formattedReplies), len(formattedMentions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
